---
title: "Prediction of academic achievement in adolescents from teacher reports of inattention in childhood - a methodological pattern classification study"
output: html_notebook
---

```{r, echo=TRUE, eval=FALSE}
~GitHub/inattention-population/code/inattention-populationsample-svn.Rmd
```

<small>
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 
Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.
When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).
</small>


## Abstract

### Background
Inattentive behavior is associated with academic problems. The present study investigates primary school teacher reports on nine items reflecting different aspects of inattention, with an aim to reveal patterns of behavior predicting high-school academic achievement. To that end, we used different types of pattern analysis and machine learning methods. 

### Methods
Inattention in a sample 2397 individuals were rated by their primary school teachers when they participated in the first wave of the Bergen Child Study (BCS) (7 - 9 years old), and their academic achievements were available from an official school register when attending high-school (16 - 19 years old). Inattention was assessed by the nine items rated at a categorical leve, and the academic achievement scores were divided into three parts including a similar number of participants. 

### Results 
Boys obtained higher inattention scores and lower academic scores than girls. Inattention problems related to sustained attention and distractibility turned out to have the highest predictive value of academic achievement level across all selected statistical analyses, and the full model showed that inattention explained about 10\% of the variance in high school scores about 10 years later. A high odds-ration of being allocated to the lowest academic achievement category was shown by a multinominal regression analysis, while a pattern of problems related to sustained attention and distractibility was revealed by generating classification trees. By including recursive learning algorithms, the most successful classification was found between these inattention items and the highest level of achievement scores. 

### Summary 
The present study showed the importance of a pattern of early problems related to sustained attention and distractibility in predicting future academic results. By including different statistical classification models we showed that this pattern was fairly consistent. Furthermore, calculation of classification errors gave information about the uncertainty when predicting the outcome for individual children. Further studies should include a wider range of variables. 




<small>Organization of the data and the analysis:</small>

Libraries being used:

* memisc - spss.system.file()
* psych  - headTail(), describe()
* Hmisc - describe()
* pander - pander(), panderOptions()

<img src="../images/Data_to_classes_20160205_pptx.jpg" width="500px" height="500px" />

### Data preparation

Input file:

 * inattention_Arvid_new.sav (from Astri, on ~/Dropbox/Arvid_inatteion/data2)
 * inattention_nomiss_2397x12.csv
 
Output files (data):

 * inattention_nomiss_2397x12_snap_is_0_1_2.csv
 * inattention_nomiss_2397x12_snap_is_0_1.csv
 * inattention_nomiss_2397x12_snap_is_0_1_2_outcome_is_L_M_H.csv (Low, Medium, High academic score)
 * inattention_nomiss_2397x12_snap_is_0_1_2_outcome_is_0_1_2.csv (all numerical)
 * inattention_nomiss_2397x12_snap_is_N_S_C_outcome_is_L_M_H.csv (Not, Somewhat, Certainly true)
 

```{r, echo=TRUE, eval=TRUE} 
fn <- "../data2/inattention_Arvid_new.sav"
```

```{r, echo=TRUE, eval=FALSE}
# The original SPSS file as provided to AJL is
# 'inattention_Astri_94_96_new_grades_updated.sav'
# and being edited and reduced by AJL to 'inattention_Arvid_new.sav'
# Import data stored in the SPSS format
library(memisc)
fn <- "../data2/inattention_Arvid_new.sav"
data <- as.data.set(spss.system.file(fn))

# Make new data frame from the sample with the variables 
# gender, grade, SNAP1, ..., SNAP9 (vars #1-11) and
# academic_achievement (var #52) 
names(data)
d <- data[, c(1:11, 52)]
dim(d)
names(d)
str(d)
summary(d)
```

```{r, echo=TRUE, eval=TRUE}
D3 <- read.csv(file = "../data/inattention_nomiss_2397x12_snap_is_0_1_2.csv") 
C <- read.csv(file = "../data/inattention_nomiss_2397x12_snap_is_0_1_2_outcome_is_L_M_H.csv")
D <- read.csv(file = "../data/inattention_nomiss_2397x12_snap_is_N_S_C_outcome_is_L_M_H.csv")
E <- read.csv(file = "../data/inattention_nomiss_2397x12_snap_is_0_1_2_outcome_is_0_1_2.csv")
str(D3)
head(D3)
str(C)
head(C)
str(D)
head(D)
str(E)
head(E)
```



```{r, echo=TRUE, eval=TRUE}
E$averBinnedF = as.factor(E$averBinned)  # To perform clasification and not regression
E <- subset(E, select = -c(averBinned))
head(E)
```



### Using the CARET package

The caret package (short for classification and regression training) contains functions to
streamline the model training process for complex regression and classification problems.
The package utilizes a number of R packages but tries not to load them all at package
start-up. The package “suggests” field includes 27 packages. caret loads packages as
needed and assumes that they are installed. See http://topepo.github.io/caret/Logistic_Regression.html

Train the MLR or RF or ANN or SVN model on the training set (caret package)
check: to http://cran.r-project.org/web/packages/nnet/nnet.pdf, and
http://topepo.github.io/caret/training.html
The function train() sets up a grid of tuning parameters for a number of
classification and regression routines, fits each model and calculates
a resampling based performance measure.
method - a string specifying which classification or regression model to use
see http://topepo.github.io/caret/bytag.html
and https://www.byclb.com/TR/Tutorials/neural_networks/ch10_1.htm !!



```{r, echo=TRUE, eval=TRUE}
library(caret)
# Feature density plots
library(AppliedPredictiveModeling)
transparentTheme(trans = 0.4)

# plt <- featurePlot(x = E[, 1:11],
featurePlot(x = E[, 1:11],
            y = E$averBinnedF,
            plot = "density",
            scales = list(x = list(relation="free"),
                          y = list(relation="free")),
            pch = "|",
            adjust = 1.5,
            layout = c(4,3),
            ## Add a key at the top
            auto.key = list(columns = 2))
# plot(plt)
```



###  Explore the performance of another (Support Vector Machines with Radial Basis Function Kernel) classifier - svmRadial

```{r, echo=TRUE, eval=TRUE}
levels(E$averBinnedF)[levels(E$averBinnedF)=="0"] <- "L"
levels(E$averBinnedF)[levels(E$averBinnedF)=="1"] <- "M"
levels(E$averBinnedF)[levels(E$averBinnedF)=="2"] <- "H"

set.seed(998)
trainIndex <- createDataPartition(E$averBinnedF, p=.75, list=F)
# trainIndex <- createDataPartition(data$class, p=.70, list=F)
E.train <- E[trainIndex, ]
E.test <- E[-trainIndex, ]
```

```{r, echo=TRUE, eval=TRUE}
fitControl <- trainControl(   ## 10-fold CV [cross validation]
  method = "repeatedcv",
  number = 10,
  ## repeated ten times
  repeats = 10,
  classProbs = TRUE)
```

```{r, echo=TRUE, eval=TRUE}
svmFit <- train(averBinnedF ~ . , data = E.train,
                 method = "svmRadial",
                 trControl = fitControl,
                 tuneLength = 8,
                 metric = "ROC")
svmFit
```

```{r, echo=TRUE, eval=TRUE}
# Call predict on the fitted object using the test data set
E.test.svm.predict <- predict(svmFit, newdata = E.test, na.action = na.omit, verbose = TRUE)
print(summary(as.data.frame(E.test.svm.predict)))
print(summary(as.data.frame(E.test$averBinnedF)))

# Assess confusion matrix
cm.svm.fit.E.test <- confusionMatrix(E.test.svm.predict, E.test$averBinnedF)
print(cm.svm.fit.E.test)
```



